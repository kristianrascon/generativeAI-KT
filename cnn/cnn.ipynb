{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1HY60GjMZKPgBfHlbLP-7pClJjAuRDLcm","authorship_tag":"ABX9TyPSFNo94KdfYDob3mkUkP2f"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"id":"fsNJW5uXM0eo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679437105109,"user_tz":420,"elapsed":451822,"user":{"displayName":"Kristian Rascon","userId":"13766589462812670013"}},"outputId":"a14473a2-3adb-4ea4-cd42-a6b6a4179413"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1,   100] loss: 0.014\n","[2,   100] loss: 0.013\n","[3,   100] loss: 0.011\n","[4,   100] loss: 0.009\n","[5,   100] loss: 0.012\n","[6,   100] loss: 0.011\n","[7,   100] loss: 0.009\n","[8,   100] loss: 0.010\n","[9,   100] loss: 0.011\n","[10,   100] loss: 0.010\n","Finished Training\n"]}],"source":["# import torch and other necessary modules from torch\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","from sklearn.metrics import accuracy_score, recall_score, precision_score\n","...\n","# import torchvision and other necessary modules from torchvision \n","import torchvision\n","from torchvision import transforms\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","\n","...\n","\n","\n","# recommended preprocessing steps: resize to square -> convert to tensor -> normalize the image\n","# if you are resizing, 100 is a good choice otherwise GradeScope will time out\n","# you could use Compose (https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html) from transforms module to handle preprocessing more conveniently\n","transform = transforms.Compose([\n","    transforms.Resize((100, 100)),  \n","    transforms.ToTensor(),  \n","    transforms.Normalize((0.5,), (0.5,)) \n","])\n","\n","\n","# thanks to torchvision, this is a convenient way to read images from folders directly without writing datasets class yourself (you should know what datasets class is as mentioned in the documentation)\n","dataset = datasets.ImageFolder(root='./petimages', transform=transform) #./petimages for gradescope #'/content/drive/MyDrive/ASU Spring 2023/CSE 475/Labs/petimages'\n","\n","\n","# now we need to split the data into training set and evaluation set \n","# use 20% of the dataset as test\n","test_set, train_set = torch.utils.data.random_split(dataset, [int(len(dataset)*0.2), int(len(dataset)*0.8)])\n","\n","# model hyperparameter\n","learning_rate = 0.05   #between 0.001 and 0.01\n","batch_size =  32 #Powers of 2: 16,32,64,128,256,512,1024 : Default is 32\n","epoch_size = 10\n","\n","#test_set = torch.utils.data.Subset(dataset, range(n_test))  # take first 10%\n","#train_set = torch.utils.data.Subset(dataset, range(n_test, len(dataset)))  # take the rest  \n","\n","# Prepare DataLoader for training set\n","trainloader = DataLoader(train_set, batch_size = batch_size, shuffle=True)\n","\n","# Prepare DataLoader for evaluation set\n","testloader = DataLoader(test_set, batch_size = batch_size, shuffle=False)\n","\n","\n","# model design goes here\n","class CNN(nn.Module):\n","\n","    # there is no \"correct\" CNN model architecture for this lab, you can start with a naive model as follows:\n","    # convolution -> relu -> pool -> convolution -> relu -> pool -> convolution -> relu -> pool -> linear -> relu -> linear -> relu -> linear\n","    # you can try increasing number of convolution layers or try totally different model design\n","    # convolution: nn.Conv2d (https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n","    # pool: nn.MaxPool2d (https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)\n","    # linear: nn.Linear (https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n","\n","    def __init__(self):\n","        super(CNN,self).__init__()\n","        #Naive model\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3) #square kernels and equal stride\n","        self.relu1 = nn.ReLU()\n","        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # pool of square window of size=2, stride=2\n","        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3) #square kernels and equal stride\n","        self.relu2 = nn.ReLU()\n","        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # pool of square window of size=3, stride=2\n","        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3) #square kernels and equal stride\n","        self.relu3 = nn.ReLU()\n","        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # pool of square window of size=3, stride=2\n","        self.flat1 = nn.Flatten()\n","        self.lin1 = nn.Linear(in_features=64*10*10,out_features=256)\n","        self.relu4 = nn.ReLU()\n","        self.lin2 = nn.Linear(in_features=256,out_features=128)\n","        self.relu5 = nn.ReLU()\n","        self.lin3 = nn.Linear(in_features=128,out_features=2)\n","    def forward(self, x):          \n","        x = self.conv1(x)\n","        x = self.relu1(x)\n","        x = self.pool1(x)\n","        x = self.conv2(x)\n","        x = self.relu2(x)\n","        x = self.pool2(x)\n","        x = self.conv3(x)\n","        x = self.relu3(x)\n","        x = self.pool3(x)\n","        x = self.flat1(x)\n","        x = self.lin1(x)\n","        x = self.relu4(x)\n","        x = self.lin2(x)\n","        x = self.relu5(x)\n","        x = self.lin3(x)\n","        return x                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n","\n","\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu' # whether your device has GPU\n","cnn = CNN().to(device) # move the model to GPU\n","# search in official website for CrossEntropyLoss\n","criterion = nn.CrossEntropyLoss()\n","# try Adam optimizer (https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) with learning rate 0.0001, feel free to use other optimizer\n","optimizer = torch.optim.Adam(cnn.parameters(), lr=0.0001)\n","\n","\n","# start model training\n","cnn.train() # turn on train mode, this is a good practice to do\n","for epoch in range(epoch_size): # begin with trying 10 epochs \n","\n","    loss = 0.0 # you can print out average loss per batch every certain batches\n","\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs and label from dataloader\n","        inputs, labels = data\n","        # move tensors to your current device (cpu or gpu)\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # zero the parameter gradients using zero_grad()\n","        optimizer.zero_grad()\n","        # forward -> compute loss -> backward propogation -> optimize (see tutorial mentioned in main documentation)\n","        outputs = cnn(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print some statistics\n","        loss +=  loss.item()# add loss for current batch \n","        if i % 100 == 99:    # print out average loss every 100 batches\n","            print(f'[{epoch + 1}, {i + 1:5d}] loss: {loss / 100:.3f}')\n","            loss = 0.0\n","\n","print('Finished Training')\n","\n","\n","# evaluation on evaluation set\n","ground_truth = []\n","prediction = []\n","cnn.eval() # turn on evaluation model, also a good practice to do\n","with torch.no_grad(): # since we're not training, we don't need to calculate the gradients for our outputs, so turn on no_grad mode\n","    for data in testloader:\n","        inputs, labels = data\n","        inputs = inputs.to(device)\n","        ground_truth += labels.tolist() # convert labels to list and append to ground_truth\n","        # calculate outputs by running inputs through the network\n","        outputs = cnn(inputs)\n","        # the class with the highest logic is what we choose as prediction\n","        _, predicted = torch.max(outputs.data, 1)\n","        prediction += predicted.tolist()  # convert predicted to list and append to prediction\n","\n","\n","# GradeScope is chekcing for these three variables, you can use sklearn to calculate the scores\n","accuracy = accuracy_score(ground_truth, prediction)\n","recall = recall_score(ground_truth, prediction)\n","precision = precision_score(ground_truth, prediction)\n","\n","\n","\n","\n","\n","\n"]}]}